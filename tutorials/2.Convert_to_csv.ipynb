{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Set the data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flbenchmark.datasets\n",
    "\n",
    "flbd = flbenchmark.datasets.FLBDatasets('../data') # default path is './data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Convert a LEAF's dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    y          x0                            x1        x2        x3  \\\n",
      "0   0  1975480069  Sat May 30 15:14:48 PDT 2009  NO_QUERY  AceMas21   \n",
      "1   0  2053626665  Sat Jun 06 05:11:34 PDT 2009  NO_QUERY  AceMas21   \n",
      "2   0  2053716015  Sat Jun 06 05:29:00 PDT 2009  NO_QUERY  AceMas21   \n",
      "3   0  2053725526  Sat Jun 06 05:30:41 PDT 2009  NO_QUERY  AceMas21   \n",
      "4   1  1688009765  Sun May 03 10:07:32 PDT 2009  NO_QUERY  AceMas21   \n",
      "5   1  1964991402  Fri May 29 15:08:53 PDT 2009  NO_QUERY  AceMas21   \n",
      "6   1  1983327612  Sun May 31 12:56:46 PDT 2009  NO_QUERY  AceMas21   \n",
      "7   1  1996215916  Mon Jun 01 14:43:09 PDT 2009  NO_QUERY  AceMas21   \n",
      "8   1  2008558381  Tue Jun 02 14:18:37 PDT 2009  NO_QUERY  AceMas21   \n",
      "9   1  2015985635  Wed Jun 03 05:56:35 PDT 2009  NO_QUERY  AceMas21   \n",
      "10  1  2046360165  Fri Jun 05 12:04:03 PDT 2009  NO_QUERY  AceMas21   \n",
      "11  1  2063805096  Sun Jun 07 04:08:38 PDT 2009  NO_QUERY  AceMas21   \n",
      "12  1  2064351345  Sun Jun 07 06:01:23 PDT 2009  NO_QUERY  AceMas21   \n",
      "\n",
      "                                                   x4        x5  \n",
      "0   @GHmltn Oh no!!! Thats pants  I'm very classy ...  training  \n",
      "1                                       @GHmltn nope   training  \n",
      "2   @GHmltn Not in the mood for blip at the mo  So...  training  \n",
      "3                @GHmltn I know......just dont wanna   training  \n",
      "4   @Emma300 I haven't  Thanks for the offer tho  ...  training  \n",
      "5   @philkirby Haha!! Change is usually a good thi...  training  \n",
      "6     @sarahbellafina You're welcome!! Glad you like   training  \n",
      "7                       @Nuff55 Aww bless you thanks   training  \n",
      "8   @GHmltn Ahh well I'm sorry for that and if you...  training  \n",
      "9   @Lates No not pigeon sausages today!! Just abi...  training  \n",
      "10  @Dameunited I can hold a tune yes! I used to s...  training  \n",
      "11  @paulmason10538 Hiya! I'm fine thanks  Hows At...  training  \n",
      "12  @Schofe You will get loads of people asking yo...  training  \n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset = flbd.leafDatasets('sent140')\n",
    "\n",
    "flbenchmark.datasets.convert_to_csv(train_dataset, out_dir='../csv_data/sent140_train')\n",
    "flbenchmark.datasets.convert_to_csv(test_dataset, out_dir='../csv_data/sent140_test')\n",
    "\n",
    "# We use pandas to show the converted csv here. You can find the data are the same as we printed in Tutorial 1.\n",
    "import pandas as pd\n",
    "df = pd.read_csv('../csv_data/sent140_test/AceMas21.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Convert a FATE's dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id  x6  x7  x8  x9  x10  x11  x12   y  x0  x1  x2  x3  x4  x5\n",
      "0   316   5   3   3   1    2    1    0   0  18   2   1   2   2   0\n",
      "1   317   4   3   4   1    1    5    9   9  18   4   3   1   3   0\n",
      "2   318   4   3   4   2    5    5    0  10  17   3   4   1   3   0\n",
      "3   319   4   4   4   3    3    5    2  11  18   4   4   1   2   0\n",
      "4   320   5   2   2   1    2    5   23  13  17   4   3   1   2   0\n",
      "..  ...  ..  ..  ..  ..  ...  ...  ...  ..  ..  ..  ..  ..  ..  ..\n",
      "74  390   5   5   4   4    5    4   11   9  20   2   2   1   2   2\n",
      "75  391   2   4   5   3    4    2    3  16  17   3   1   2   1   0\n",
      "76  392   5   5   3   3    3    3    3   7  21   1   1   1   1   3\n",
      "77  393   4   4   1   3    4    5    0  10  18   3   2   3   1   0\n",
      "78  394   3   2   3   3    3    5    5   9  19   1   1   1   1   0\n",
      "\n",
      "[79 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset = flbd.fateDatasets('student_horizontal')\n",
    "\n",
    "flbenchmark.datasets.convert_to_csv(train_dataset, out_dir='../csv_data/student_horizontal_train')\n",
    "flbenchmark.datasets.convert_to_csv(test_dataset, out_dir='../csv_data/student_horizontal_test')\n",
    "\n",
    "# We use pandas to show the converted csv here. You can find the data are the same as we printed in Tutorial 1.\n",
    "df = pd.read_csv('../csv_data/student_horizontal_test/student_homo_test.csv')\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d47088ab44ca92c5be0367b8dfbd8c9e1db35c93d0b8c6e085b0f12e6cb59701"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('flb': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
